---
title: Genshin Impact Anki deck
permalink: "/{{ page.fileSlug }}/"
date: 2022-05-03
last_modified: 2025-06-05
description: 1000 Note Japanese vocab Anki deck and the workflow on how I made it playing video games
publicTags:
  - Language
  - Learning
  - Japanese
image: tekisetsu.png
---
It's quite the tradition among Japanese learners to publish parts of their [Anki](https://apps.ankiweb.net/) [Mining](https://animecards.site/learningjapanese/) decks, so others may get inspired by them or straight up use them. This ~1000 note deck is an excerpt of my Mining deck, which was/is being created in-part from the video game [Genshin Impact](https://genshin.hoyoverse.com/en/home).

> **Mining as defined by [animecards](https://animecards.site/learningjapanese/):** *A mining deck is a custom Anki deck that you create using the Japanese you encounter daily. Transitioning from pre-made decks to custom decks is vital. Don't get stuck on pre-made decks. At this point, you're learning directly from material relevant to you and targeting gaps in your knowledge.*

[**Link to the deck on Ankiweb**](https://ankiweb.net/shared/info/870567459) (If AnkiWeb ends up pulling the deck due to copyright concerns, a copy is in the release section [here](https://github.com/FrostKiwi/treasurechest/releases/download/genshindeckv1/Genshin.Impact.Japanese.with.media.apkg)) All cards have in-game sound + screenshot and almost all have additionally a dictionary sound file + pitch accent.

![image](tekisetsu.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="teki_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="teki_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

This post will go into the thought process behind the deck, how it was created and has sound clips below every screenshot for reference. Of course, using someone else's Mining deck doesn't carry nearly the same benefit as making one yourself, so this article is mainly to just document my workflow and to provide a jumping-off point for people setting up their own.

## Why Genshin Impact?

A couple of things come together to make Genshin quite the enjoyable learning experience. The obvious first: Except minor side quests, all dialogs are voiced and progress sentence by sentence, click by click, as is common in JRPGs and visual novels. This gives enough time to grasp the dialog's content. 

<blockquote class="reaction"><div class="reaction_text">In-game time does not stop during dialogs except in some quests, so sometimes multiple in-game days would pass by, as I grasped the contents of a dialog.</div><img class="kiwi" src="/assets/kiwis/laugh.svg"></blockquote>

Another point is the writing style. A hotly debated topic in the player-base, is whether or not the addition of [Paimon](https://genshin-impact.fandom.com/wiki/Paimon) hurts the delivery of the story. The character constantly summarizes events happening and repeats commands or requests, that were given by another character just moments ago during dialog.

The main criticism often brought up is that this makes the story-flow very child-like, which is a rather obvious design goal of the game - catering to a younger audience. What may be a sore in the eyes of many a player though, is a godsend in the eyes of a language learner. Paimon often describes a situation, which was witnessed by the player mere moments ago, making the actual statement of a sentence trivial to understand.

![image](tsurusu.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="tsurusu_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="tsurusu_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

And sometimes Paimon straight up becomes a dictionary herself and defines a word like a glossary text would.

![image](oru.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="oru_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="oru_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

There is a very dialog- and lore-heavy story-line in Dragonspine involving Albedo, which has some of the most information dense dialog of the game. Paimon often commented, how she completely lost the plot and didn't understand anything. During that story line I felt as if Paimon was sympathizing with me, as I battled my way to understanding that story-line.

<blockquote class="reaction"><div class="reaction_text">For me, Paimon really made this game shine as a learning tool.</div><img class="kiwi" src="/assets/kiwis/book.svg"></blockquote>

### The good outcome

I'm constantly surprised how much Genshin has propelled my speech forward. Similar to a movie you can quote decades later or video game moments being etched into memory.

<blockquote class="reaction"><div class="reaction_text">There is something about the media we consume, that makes it stick.</div><img class="kiwi" src="/assets/kiwis/think.svg"></blockquote>

I found myself using and recalling vocabulary acquired via Genshin faster than from other sources. Or maybe it's just that video games make you engage with their world and characters for far longer and with much more intensity, than other forms of indirect-study could.

### The dangerous outcome

It's common knowledge that media uses artistic delivery in speech, has speech patterns rarely used in everyday life and uses a stylized way of writing. Basically all of it is [役割語](https://ja.wikipedia.org/wiki/%E5%BD%B9%E5%89%B2%E8%AA%9E). Knowing that full well I *still* managed to trip up. Case in point:

![image](homare.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="homare_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="homare_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

I used the 誉れです expression instinctively from time to time and just recently someone noted, that this expression has a rather archaic, regal tone. It was quite the funny situation, but it goes to show, that even knowing what kind of media I was consuming still didn't save me from tripping up.

Coming from outside the language it's unavoidable to misinterpret an expression's nuance I guess. Though in this case, the in-game dialog should have really tipped me off, as the character speaking, Ninguang, uses it to tell a joke with a somewhat sarcastic undertone.

## Info and Structure

- Since this is a mining vocabulary deck, it carries words \*I\* did not know during in-game dialog. I already finished the [Improved Core3k](https://ankiweb.net/shared/info/1060896809) deck, so there are zero duplicates between this deck and Core3k. Besides that, I started the deck shortly before my N4 exam and am now ~~N3~~ N2. Words in the deck are essentially N3 and up, with some easy ones sprinkled in. No in-universe words are saved, like モラ or 目狩り令.
- The deck captures the main story-line and a few side-quests / story-quests from the beginning up to Inzuma's second chapter.
- I always learn both Japanese -> English, as well as English -> Japanese. This point is hotly debated, whether or not it's useful or a massive waste of time. For me switching to learning both directions has been nothing but great, but it is not the default on Anki Web and not a popular opinion it seems. To fit with the default, I have disabled the English -> Japanese Card type.

<blockquote class="reaction"><div class="reaction_text">Personally, if I can name a synonym in the <strong>English -> Japanese</strong> direction, I still let it pass as <strong>HARD</strong> and as <strong>AGAIN</strong> if I can only name a synonym, once the card returns</div><img class="kiwi" src="/assets/kiwis/book.svg"></blockquote>

- For the in-game subtitles OCR sometimes failed. I corrected small mistakes, but when it output complete garbage, I added a cropped version of just the text in the screenshot for the sentence section. I did not always double check the OCR output, so mistakes will come up in the in-game dialog's transcript occasionally. If something looks weird with the example sentences, check the in-game screenshot for the correct transcript.
- To fit inside the AnkiWeb limit of 256 MB, all images were resized from the 1080p originals to fit a 1366x768 rectangle with aggressive 81% JPEG Quality and in-game dialog are mono MP3 files.
- When I write "***here: ...***", I am referring to a word being used in a more specialized sense in the in-game dialog, like 人目 vs 人目を忍ぶ. In those cases two definitions are provided. This is to make the learning process a bit more compact and to prevent not being able to translate a sentence, whilst having just half of the definition.

![hitome](hitome.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="hitome_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="hitome_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

- Characters speaking Kansai dialect have received there own tag "Kansaidialect".

![meccha](meccha.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="meccha_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="meccha_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

### Grammar

I also have a bunch of grammar cards mixed in, when I encountered new pieces of grammar and recognized it as such. For those I pasted the excellent [JLPT Sensei](https://jlptsensei.com/) summary images.

![kireicake](tohaie.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="tohaie_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="tohaie_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

A big surprise to me was the [YomiChan](https://github.com/FooSoft/yomichan) dictionary ["KireiCake"](https://foosoft.net/projects/yomichan/#dictionaries) having URL-shortened links from time to time, like [waa.ai/v4YY](https://waa.ai/v4YY) in the above card. In this case it leads to an [in-depth discussion on Yahoo](https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q1317655948) about that grammar point. [(Archive Link, in case it goes down)](http://web.archive.org/web/20220508092155/https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q1317655948)

The love and patience of the Japanese learning online community is truly magnificent. From /djt/ threads on image-boards to [user-scripts connecting Kanji learn services to a collection of example recordings from Anime.](https://community.wanikani.com/t/userscript-anime-context-sentences/54003?u=frostkiwi)

<blockquote class="reaction"><div class="reaction_text">This dedication to help each other out like that has me in awe.</div><img class="kiwi" src="/assets/kiwis/love.svg"></blockquote>

### To translate or not to translate

In the beginning I did toggle to English to screenshot the English version for the card's back-side, see the example card below. However, on recommendation from members of the [English-Japanese Language Exchange discord server](https://discord.com/invite/japanese), I stopped doing so. Mainly, because of localization discrepancies between both versions.

Differences got especially heavy, when more stylized dialogue got involved. But also in part, because this is not recommended for mining in general. Quoting from the Core3k description:

> Don't use the field 'Sentence-English' in your mined cards. In fact, get rid of it once you have a solid understanding of Japanese. When you mine something you should already have understood the sentence using the additional information on your cards.

![image](unmei.png)
<div class="audio-container">
    <div>
        Dictionary Audio
        <audio controls>
            <source src="unmei_dict.mp3" type="audio/mpeg">
        </audio>
    </div>
    <div>
        In-game Audio
        <audio controls>
            <source src="unmei_game.mp3" type="audio/mpeg">
        </audio>
    </div>
</div>

## How it was captured

If you are completly new to the Mining workflow, check out [AnimeCards.site](https://animecards.site/) before jumping into my specific workflow.

The main workhorse of everything is [Game2Text](https://game2text.com/), though the setup in the case of Genshin is not straight forward. Game2Text is a locally run server, that opens as localhost in your browser. Game2Text then allows you to combine a couple of things:

Capture a window's content via FireFox's and Chrome's native window capture feature, run a region of the window through OCR, like the offline and opensource [tesseract](https://github.com/tesseract-ocr/tesseract) or the more powerful online service [ocr.Space](https://ocr.space/) and finally allow you to translate the text with help of popular plug-ins like [YomiChan](https://github.com/FooSoft/yomichan) or the new active community fork [YomiTan](https://github.com/themoeway/yomitan).

Game2Text has native Anki Connect integration, which builds Anki cards from the captured screenshot, the currently selected word and a dictionary definiton. However, this native Anki integration sometimes fails to recognize phrases, that more complex dictionary suites in YomiChan detect. Luckily Game2Text can essentially give you the best of both worlds, since you can just use directly YomiChan to create a card.

<blockquote class="reaction"><div class="reaction_text">Though in that case, you have to handle screenshots yourself.</div><img class="kiwi" src="/assets/kiwis/detective.svg"></blockquote>

Genshin fails to get captured by the browser, unless it is in window mode. There is no proper borderless window mode in Genshin unfortunately, unless you use a [patcher to get a borderless window](https://github.com/Codeusa/Borderless-Gaming). Another option is to run [OBS](https://github.com/obsproject/obs-studio) in administrator mode, capture the game, open up a full-screen "source monitor"-window of Genshin's source signal and let the browser capture that.

<blockquote class="reaction"><div class="reaction_text">This is the option I went with on my Desktop PC.</div><img class="kiwi" src="/assets/kiwis/happy.svg"></blockquote>

On my Laptop with a dedicated Nvidia GPU this leads to massive performance loss however, presumably because of saturating memory bandwidth due to some weird interaction between the iGPU and the main GPU causing a memory bottleneck somehow. In that case I used the borderless gaming patcher.

If Game2Text has a hook-script for the game in question, then it can hook into the game's memory and read out the dialog strings, forgoing the sometimes imprecise OCR. No such hook-script exists for Genshin Impact (to my knowledge).I decided to drop that approach due to the worry of having my account banned.

<blockquote class="reaction"><div class="reaction_text">If OCR is imprecise, there is always the onscreen dialog box to check against.</div><img class="kiwi" src="/assets/kiwis/teach.svg"></blockquote>

### Handling Audio

Across multiple systems, Game2Text fails to create a card with sound for me though. It successfully captures sound in .wav files, but transcodes them to fully silent .mp3 files, which it attaches to the cards. So instead of working with the .wav files, I simply let [Audacity](https://github.com/audacity/audacity) capture the sound output via its "Windows WASAPI" mode and the thus unlocked speaker loopback record method in a non-stop recording. On dialog I would select the needed passage and via a macro bound to a hot-key, perform the conversion to mono, normalization and export to an mp3 file.

Originally, I set all audio to be normalized based on setting the peak sample to -3db via Audacity. This turned out to be not quite optimal, as the amount of voice profiles is very broad. With peak sample normalization bright and dark voices did not end up playing back at the same loudness, since it does not account for human hearing being more sensitive to some frequencies compared others.

I batch-reencoded every audio file to be normalized to -15LUFS loudness instead [(Conversion workflow explained here)](https://www.reddit.com/r/LearnJapanese/comments/un94c0/comment/i8e5etb/?utm_source=share&utm_medium=web2x&context=3), the more modern approach. Although the difference was subtle, the dialogue sounded a bit more balanced from card to card after that.

It would be optimal to have no music mixed in with the dialog for the sake of cleaner dialog sound during card reviews. However, the music is so incredibly good, that it would have not been even half as enjoyable to go through the game without the music. So often background music plays with the cards.

<blockquote class="reaction"><div class="reaction_text">Worst offender being Liyue Harbor's background track, which manages to drown out dialog <a href="https://youtu.be/t1O7LpOTBfM?t=318" target="_blank">during its crescendo</a>.</div><img class="kiwi" src="/assets/kiwis/tired.svg"></blockquote>

### The actual workflow

When I did not recognize a word, I would tab out of the game, select the rectangle in Game2Text to get the transcript. I would then use YomiChan to aid me in understanding the sentence. When the "logs" screen of Game2Text properly recognized the phrase in question, I would then use it to create the card. 

When not, I would use YomiChan and manually post the screenshot. Also, I screenshot YomiChan's PitchAccent display and paste it into the reading field. Finally, I would tab into audacity, select the needed passage, press the hotkey to export the sound as an mp3 into a folder I had open and Drag&Drop to the current Anki card.

Sometimes there was no dictionary sound reading in the Game2Text log screen, but in YomiChan - or vice-versa. In that case I would play the dictionary sound from the other source, let Audacity capture it and again export that sound passage. (Technically you can get the sound file directly or by creating a duplicate card, but that was too much of a hassle)

Finally, if none of the two sources had a dictionary reading, I would manually check the [JapanesePod101 dictionary](https://www.japanesepod101.com/japanese-dictionary/), which surprisingly has a ton of obscure vocab readings as sound files. Just make sure to un-tick 'most common 20.000 words', tick 'Include vulgar words' and switch the mode from 'ls' to 'Starts with' to find more complex phrases.

<blockquote class="reaction"><div class="reaction_text">This concludes my little write-up about the Genshin Impact part of my Anki mining deck. Hope you found it useful.</div><img class="kiwi" src="/assets/kiwis/happy.svg"></blockquote>
